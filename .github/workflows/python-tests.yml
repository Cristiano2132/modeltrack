name: Run Tests

on:
  push:
    branches: ["main", "develop"]
  pull_request:
    branches: ["main"]

permissions:
  contents: read

jobs:
  build:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      # Instala Java (necess√°rio para PySpark)
      - name: Set up Java
        id: setup-java
        uses: actions/setup-java@v3
        with:
          distribution: 'temurin'
          java-version: '21'  # Spark funciona bem com Java 21

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt
          pip install .

      - name: Lint with flake8
        run: |
          flake8 src tests --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 src tests --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Run tests with coverage
        env:
          JAVA_HOME: ${{ steps.setup-java.outputs.java-home }}
          PATH: ${{ steps.setup-java.outputs.java-home }}/bin:$PATH
        run: |
          echo "Using Java from $JAVA_HOME"
          java -version
          coverage run --source=modeltrack -m unittest discover -s tests
          coverage report --fail-under=80